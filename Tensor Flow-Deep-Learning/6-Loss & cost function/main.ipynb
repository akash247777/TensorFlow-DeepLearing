{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Cost Functions in Deep Learning\n",
    "\n",
    "In deep learning, loss and cost functions are used to measure how well a model is performing. They help the model learn by telling it how far its predictions are from the actual correct answers.\n",
    "\n",
    "## Loss Function\n",
    "\n",
    "The loss function measures the error for a single training example. It calculates how far the model's prediction is from the actual target value.\n",
    "\n",
    "Think of it as a way to tell the model, \"This is how wrong you were for this one example.\"\n",
    "\n",
    "### Example\n",
    "\n",
    "Let’s say you’re predicting house prices. For one house:\n",
    "\n",
    "- **Actual price**: $300,000\n",
    "- **Model’s prediction**: $250,000\n",
    "\n",
    "The loss function (e.g., Mean Squared Error) would calculate the difference:\n",
    "\n",
    "\n",
    "\n",
    "\\[ \\text{Loss} = (300,000 - 250,000)^2 = 50,000^2 = 2,500,000,000 \\]\n",
    "\n",
    "\n",
    "\n",
    "This tells the model, \"You were off by $50,000 for this house.\"\n",
    "\n",
    "## Cost Function\n",
    "\n",
    "The cost function is the average loss over the entire dataset. It measures how well the model is performing across all training examples.\n",
    "\n",
    "Think of it as the model’s overall \"report card\" for its predictions.\n",
    "\n",
    "### Example\n",
    "\n",
    "If you have 3 houses with the following predictions:\n",
    "\n",
    "- **Actual**: 300,000, **Predicted**: 250,000 → **Loss**: 50,000² = 2,500,000,000\n",
    "- **Actual**: 400,000, **Predicted**: 420,000 → **Loss**: 20,000² = 400,000,000\n",
    "- **Actual**: 500,000, **Predicted**: 480,000 → **Loss**: 20,000² = 400,000,000\n",
    "\n",
    "The cost function (average loss) would be:\n",
    "\n",
    "\n",
    "\n",
    "\\[ \\text{Cost} = \\frac{2,500,000,000 + 400,000,000 + 400,000,000}{3} = \\frac{3,300,000,000}{3} = 1,100,000,000 \\]\n",
    "\n",
    "\n",
    "\n",
    "This tells the model, \"On average, your predictions are off by a lot.\"\n",
    "\n",
    "## Why Are They Important?\n",
    "\n",
    "The goal of training a model is to minimize the cost function. This means making the model’s predictions as close as possible to the actual values.\n",
    "\n",
    "During training, the model adjusts its parameters (weights and biases) to reduce the cost function, improving its predictions.\n",
    "\n",
    "## Common Loss/Cost Functions\n",
    "\n",
    "- **Mean Squared Error (MSE)**: Used for regression tasks (e.g., predicting house prices).\n",
    "- **Cross-Entropy Loss**: Used for classification tasks (e.g., classifying images as cats or dogs).\n",
    "- **Binary Cross-Entropy Loss**: Used for binary classification (e.g., spam or not spam).\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **Loss function**: Measures error for one example.\n",
    "- **Cost function**: Measures average error for the entire dataset.\n",
    "\n",
    "Both help the model learn by quantifying how wrong its predictions are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Mean Absolute error, Mean Squared error, log loss or Binary Cross-Entropy\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "\n",
    "**What it is**: MAE measures the average absolute difference between the predicted and actual values.\n",
    "\n",
    "**Formula**:\n",
    "\n",
    "\n",
    "\n",
    "$$ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} | y_i - \\hat{y}_i | $$\n",
    "\n",
    "\n",
    "\n",
    "- $y_i$= actual value\n",
    "- $ \\hat{y}_i $ = predicted value\n",
    "- $n$ = number of examples\n",
    "\n",
    "**Example**:\n",
    "Suppose you’re predicting house prices:\n",
    "\n",
    "- Actual prices: [300, 400, 500]\n",
    "- Predicted prices: [250, 420, 480]\n",
    "\n",
    "Calculate absolute errors:\n",
    "\n",
    "- |300 - 250| = 50\n",
    "- |400 - 420| = 20\n",
    "- |500 - 480| = 20\n",
    "\n",
    "\n",
    "\n",
    "$$\\text{MAE} = \\frac{50 + 20 + 20}{3} = 30$$\n",
    "\n",
    "\n",
    "\n",
    "**Interpretation**: On average, the model’s predictions are off by $30,000.\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "\n",
    "**What it is**: MSE measures the average squared difference between the predicted and actual values. It penalizes larger errors more heavily.\n",
    "\n",
    "**Formula**:\n",
    "\n",
    "\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} ( y_i - \\hat{y}_i )^2$$\n",
    "\n",
    "\n",
    "\n",
    "**Example**:\n",
    "Using the same house prices:\n",
    "\n",
    "- Actual prices: [300, 400, 500]\n",
    "- Predicted prices: [250, 420, 480]\n",
    "\n",
    "Calculate squared errors:\n",
    "\n",
    "- (300 - 250)² = 2500\n",
    "- (400 - 420)² = 400\n",
    "- (500 - 480)² = 400\n",
    "\n",
    "\n",
    "\n",
    "$$ \\text{MSE} = \\frac{2500 + 400 + 400}{3} = 1100 $$\n",
    "\n",
    "\n",
    "\n",
    "**Interpretation**: On average, the model’s predictions are off by 1100 squared units. This is harder to interpret directly, but it’s useful for optimization.\n",
    "\n",
    "# Log Loss (Binary Cross-Entropy)\n",
    "\n",
    "**What it is**: Log Loss measures the performance of a binary classification model (e.g., predicting 0 or 1). It penalizes incorrect predictions and rewards confident, correct predictions.\n",
    "\n",
    "**Formula**:\n",
    "\n",
    "\n",
    "\n",
    "$$\\text{Log Loss} = -\\frac{1}{n} \\sum_{i=1}^{n} [ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) ]$$\n",
    "\n",
    "\n",
    "\n",
    "- $y_i$ = actual label (0 or 1)\n",
    "- $ \\hat{y}_i$ = predicted probability (between 0 and 1)\n",
    "\n",
    "**Example**:\n",
    "Suppose you’re predicting whether an email is spam (1) or not spam (0):\n",
    "\n",
    "- Actual labels: [1, 0, 1]\n",
    "- Predicted probabilities: [0.9, 0.2, 0.7]\n",
    "\n",
    "Calculate log loss:\n",
    "\n",
    "- For $y_1$ = 1, $\\hat{y}_1$ = 0.9 : $ -\\log(0.9)$    = 0.105 \n",
    "- For $y_2$ = 0, $\\hat{y}_2$ = 0.2 : $-\\log(1 - 0.2)$ = 0.223\n",
    "- For $y_3$ = 1, $ \\hat{y}_3$= 0.7 : $-\\log(0.7)$     = 0.357 \n",
    "\n",
    "\n",
    "\n",
    "$$ \\text{Log Loss} = \\frac{0.105 + 0.223 + 0.357}{3} = 0.228$$\n",
    "\n",
    "\n",
    "\n",
    "**Interpretation**: A lower log loss means better predictions. Here, the model is doing reasonably well, but there’s room for improvement.\n",
    "\n",
    "# Key Differences\n",
    "\n",
    "| Metric | Use Case | Behavior | Example Interpretation |\n",
    "|--------|----------|----------|------------------------|\n",
    "| MAE    | Regression | Measures average absolute error | Predictions are off by $30,000 on average. |\n",
    "| MSE    | Regression | Penalizes larger errors more | Predictions are off by 1100 squared units. |\n",
    "| Log Loss | Binary Classification | Rewards confident, correct predictions | Lower log loss = better model performance. |\n",
    "\n",
    "# When to Use Which?\n",
    "\n",
    "- Use MAE if you want a simple, interpretable measure of error.\n",
    "- Use MSE if you want to penalize larger errors more heavily (useful for optimization).\n",
    "- Use Log Loss for binary classification problems where you need to measure probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why We Use Mean Absolute Error, Mean Squared Error, Log Loss or Binary Cross-Entropy\n",
    "\n",
    "The choice of Mean Absolute Error (MAE), Mean Squared Error (MSE), or Log Loss (Binary Cross-Entropy) depends on the type of problem you're solving (regression or classification) and the specific behavior you want from your model. Let’s break it down:\n",
    "\n",
    "## 1. Mean Absolute Error (MAE)\n",
    "\n",
    "### Why Use It?\n",
    "- **Interpretability**: MAE is easy to understand because it directly measures the average absolute difference between predictions and actual values.\n",
    "- **Robustness to Outliers**: MAE is less sensitive to outliers compared to MSE because it doesn’t square the errors. This makes it a good choice when your data has noisy or extreme values.\n",
    "\n",
    "### When to Use It?\n",
    "Use MAE for regression problems where you want a simple, interpretable measure of error.\n",
    "\n",
    "**Example**: Predicting house prices, where outliers (e.g., extremely expensive houses) shouldn’t dominate the error metric.\n",
    "\n",
    "## 2. Mean Squared Error (MSE)\n",
    "\n",
    "### Why Use It?\n",
    "- **Penalizes Larger Errors**: MSE squares the errors, so larger errors contribute disproportionately to the total error. This encourages the model to focus on reducing large errors.\n",
    "- **Useful for Optimization**: Many optimization algorithms (like gradient descent) work well with MSE because it’s differentiable and has a smooth curve.\n",
    "\n",
    "### When to Use It?\n",
    "Use MSE for regression problems where you want to penalize large errors heavily.\n",
    "\n",
    "**Example**: Predicting stock prices, where being wildly wrong is much worse than being slightly wrong.\n",
    "\n",
    "## 3. Log Loss (Binary Cross-Entropy)\n",
    "\n",
    "### Why Use It?\n",
    "- **Probabilistic Interpretation**: Log Loss measures the performance of a model that outputs probabilities (e.g., the probability of an email being spam). It rewards confident and correct predictions while penalizing incorrect or uncertain ones.\n",
    "- **Useful for Classification**: It’s specifically designed for binary classification problems, where the goal is to predict one of two classes (e.g., spam or not spam).\n",
    "\n",
    "### When to Use It?\n",
    "Use Log Loss for binary classification problems where the model outputs probabilities.\n",
    "\n",
    "**Example**: Predicting whether a customer will churn (yes or no), where you want to measure how well the model’s predicted probabilities match the actual outcomes.\n",
    "\n",
    "## Key Differences and Use Cases\n",
    "\n",
    "| Metric   | Use Case              | Key Behavior                                      | Example Use Case                                |\n",
    "|----------|-----------------------|---------------------------------------------------|-------------------------------------------------|\n",
    "| MAE      | Regression            | Measures average absolute error. Robust to outliers. | Predicting house prices with noisy data.        |\n",
    "| MSE      | Regression            | Penalizes larger errors more heavily.             | Predicting stock prices where large errors are costly. |\n",
    "| Log Loss | Binary Classification | Measures probabilistic accuracy. Rewards confident, correct predictions. | Predicting spam emails (yes/no).                |\n",
    "\n",
    "## Why Not Use Just One Metric?\n",
    "Each metric has its strengths and weaknesses, and the choice depends on:\n",
    "\n",
    "- **Problem Type**: Regression vs. classification.\n",
    "- **Data Characteristics**: Presence of outliers, noisy data, etc.\n",
    "- **Model Behavior**: Whether you want to penalize large errors (MSE) or treat all errors equally (MAE).\n",
    "- **Output Type**: Probabilities (Log Loss) vs. direct values (MAE/MSE).\n",
    "\n",
    "## Summary\n",
    "- Use MAE for simple, interpretable regression tasks with potential outliers.\n",
    "- Use MSE for regression tasks where large errors are particularly bad.\n",
    "- Use Log Loss for binary classification tasks where the model outputs probabilities.\n",
    "\n",
    "By choosing the right metric, you ensure that your model is optimized for the specific problem you’re solving!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted values (e.g., from a model)\n",
    "y_predicted = np.array([1, 1, 0, 0, 1])\n",
    "\n",
    "# True values (e.g., actual labels)\n",
    "y_true = np.array([0.30, 0.7, 1, 0, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_predicted, y_true):\n",
    "    # Initialize the total error to 0\n",
    "    total_error = 0\n",
    "    \n",
    "    # Loop over the predicted and true values\n",
    "    for yp, yt in zip(y_predicted, y_true):\n",
    "        # Calculate the absolute error for each prediction\n",
    "        total_error += abs(yp - yt)\n",
    "    \n",
    "    # Print the total error\n",
    "    print(\"Total error is:\", total_error)\n",
    "    \n",
    "    # Calculate the mean absolute error\n",
    "    mae = total_error / len(y_predicted)\n",
    "    \n",
    "    # Print the mean absolute error\n",
    "    print(\"Mean absolute error is:\", mae)\n",
    "    \n",
    "    # Return the mean absolute error\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error is: 2.5\n",
      "Mean absolute error is: 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_predicted, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement same thing using numpy in much easier way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7, 0.3, 1. , 0. , 0.5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(y_predicted - y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(y_predicted-y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_np(y_predicted, y_true):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Absolute Error (MAE) between predicted and true values.\n",
    "\n",
    "    MAE is a measure of errors between paired observations expressing the same phenomenon.\n",
    "\n",
    "    Parameters:\n",
    "    y_predicted (numpy.ndarray): The predicted values.\n",
    "    y_true (numpy.ndarray): The true values.\n",
    "\n",
    "    Returns:\n",
    "    float: The mean absolute error between the predicted and true values.\n",
    "    \"\"\"\n",
    "    # Calculate the mean absolute error\n",
    "    return np.mean(np.abs(y_predicted-y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_np(y_predicted, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Log Loss or Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1740\\262464415.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log([0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-inf])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-34.53877639])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log([1e-15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1e-15, 1e-15, 1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "y_predicted_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1e-15, 1e-15, 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "y_predicted_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999999999999999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.999999999999999, 0.999999999999999, 1e-15, 1e-15, 0.999999999999999]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
    "y_predicted_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.99200722e-16, -9.99200722e-16, -3.45387764e+01, -3.45387764e+01,\n",
       "       -9.99200722e-16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_new = np.array(y_predicted_new)\n",
    "np.log(y_predicted_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Log Loss} = -\\frac{1}{n} \\sum_{i=1}^{n} [ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) ]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.2696280766844"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_true, y_predicted):\n",
    "    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.2696280766844"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_true, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing mean squared error (or MSE) in two ways,\n",
    "\n",
    "1. Without using numpy (i.e. using plain python)\n",
    "\n",
    "2. With the use of numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 1: Without using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Predicted values (e.g., from a model)\n",
    "y_predicted = np.array([1, 1, 0, 0, 1])\n",
    "\n",
    "# True values (e.g., actual labels)\n",
    "y_true = np.array([0.30, 0.7, 1, 0, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_predicted, y_true):\n",
    "    # Initialize the total error to 0\n",
    "    total_error = 0\n",
    "    \n",
    "    # Loop over the predicted and true values\n",
    "    for yp, yt in zip(y_predicted, y_true):\n",
    "        # Calculate the absolute error for each prediction\n",
    "        total_error += abs(yp - yt)**2\n",
    "    \n",
    "    # Print the total error\n",
    "    print(\"Total error is:\", total_error)\n",
    "    \n",
    "    # Calculate the mean absolute error\n",
    "    mae = total_error / len(y_predicted)\n",
    "    \n",
    "    # Print the mean absolute error\n",
    "    print(\"Mean absolute error is:\", mae)\n",
    "    \n",
    "    # Return the mean absolute error\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error is: 1.83\n",
      "Mean absolute error is: 0.366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.366"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_predicted, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 2: By using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.366"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.square(y_true-y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
